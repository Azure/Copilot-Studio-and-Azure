# Lab 1.4: Use Advanced Querying with Azure AI Search in Copilot Studio

## Objectives
1. Design and build an Azure AI Search index optimized for RAG.
2. Implement ingestion, chunking, vectorization, semantic ranking, and scoring profiles.
3. Explore hybrid and semantic queries, filters, and evaluation metrics.
4. Integrate the index with a Copilot Studio agent using:
   - Knowledge Source (quick setup)
   - HTTP connector (full control)
   - Real-time knowledge connectors
5. Orchestrate a controlled RAG pipeline in Copilot Studio with tools and prompts.

## Contents

In this lab, you will perform the actions necessary to connect Azure AI Search to your Copilot Studio agent and use it to generate responses.

## Prerequisites

Before starting this lab, ensure you have completed the following prerequisites:

- **[Lab 0.0 - Create an agent](./0.0-create-an-agent.md)** 
- **[Scripts 1.4 - Deploy Resources for AI Search](../scripts/lab-1.4/terraform/readme.md)**
- **[Lab 1.4 - Using AI Search](./1.4-aisearch.md)**

## Estimated Completion Time

45 minutes

## Exercise 1: Create a Index in Azure AI Search

### Task 1: Create a Container and Upload Document

1.	Navigate to the storage account created in the prerequisites and select **Containers** under Data storage. 

2. Click on **+ Container** to create a new container. 

3. In the **New container** pane, enter a name for the container (e.g., `Documents2Index`), set the **Public access level** to `Private (no anonymous access)`, and click **Create**.

4. When the container is created, click on its name to open it.

5. Click on **Upload** to upload a document. In the **Upload blob** pane, click on the folder icon to select a file from your local machine. Choose a document and click **Upload**.

### Task 2: Create an Data Source in Azure AI Search

1. Navigate to the Azure AI Search service created in the prerequisites.

2. In the left-hand menu, select **Data sources** and then click on **+ Add data source**.

3. In the **New data source** pane, enter a name for the data source (e.g., `Documents2Index`).

4. For the **Data source type**, select `Azure Blob Storage`.

5. For the **Storage account**, select the storage account you created in the prerequisites.

6. For the **Container**, select the container you created in Task 1.

### Task 3: Create an Index in Azure AI Search

1. In the Azure AI Search service, select **Indexes** from the left-hand menu and click on **+ Add index** and then select **Add index (JSON)**.

2. copy and paste the following JSON schema into the editor, replacing any existing content. This schema defines the fields and settings for your index.

```json
{
  "name": "rag-knowledge-index",
  "fields": [
    {
      "name": "chunk_id",
      "type": "Edm.String",
      "key": true,
      "searchable": false
    },
    {
      "name": "chunk_text",
      "type": "Edm.String",
      "searchable": true,
      "analyzer": "en.microsoft"
    },
    {
      "name": "chunk_vector",
      "type": "Collection(Edm.Single)",
      "searchable": true,
      "dimensions": 3072,
      "vectorSearchProfile": "vector-profile-1"
    },
    {
      "name": "source_url",
      "type": "Edm.String",
      "searchable": false,
      "filterable": true,
      "facetable": true
    },
    {
      "name": "tags",
      "type": "Collection(Edm.String)",
      "searchable": true,
      "filterable": true,
      "facetable": true
    },
    {
      "name": "locale",
      "type": "Edm.String",
      "searchable": false,
      "filterable": true
    },
    {
      "name": "created_date",
      "type": "Edm.DateTimeOffset",
      "filterable": true,
      "sortable": true
    }
  ],
  "vectorSearch": {
    "algorithms": [
      {
        "name": "hnsw-algorithm-1",
        "kind": "hnsw",
        "hnswParameters": {
          "metric": "cosine",
          "m": 4,
          "efConstruction": 400,
          "efSearch": 500
        }
      }
    ],
    "profiles": [
      {
        "name": "vector-profile-1",
        "algorithm": "hnsw-algorithm-1",
        "vectorizer": "openai-vectorizer-1"
      }
    ],
    "vectorizers": [
      {
        "name": "openai-vectorizer-1",
        "kind": "azureOpenAI",
        "azureOpenAIParameters": {
          "resourceUri": "https://YOUR-OPENAI-RESOURCE.openai.azure.com",
          "deploymentId": "text-embedding-3-large",
          "modelName": "text-embedding-3-large",
          "apiKey": "YOUR-OPENAI-API-KEY"
        }
      }
    ]
  }
}
```

3. Click **Create** to save the index. 

    > **Warning**: Before creating the index, make sure to replace `YOUR-OPENAI-RESOURCE` with your actual Azure OpenAI resource endpoint and `YOUR-OPENAI-API-KEY` with your actual API key in the JSON schema above.

4. The index will be created and will appear in the **Indexes** list.

### Task 4: Create a Skillset in Azure AI Search

1. In the Azure AI Search service, select **Skillsets** from the left-hand menu and click on **+ Add skillset**.

2. In the **New skillset** pane, copy and paste the following JSON schema into the editor, replacing any existing content. This schema defines the skills for processing documents, including chunking and embedding.

```json
{
    "name": "rag-knowledge-skillset",
    "description": "Skillset for processing documents with chunking and embedding",
    "skills": [
        {
            "@odata.type": "#Microsoft.Skills.Text.SplitSkill",
            "name": "text-split",
            "description": "Split text into chunks",
            "context": "/document",
            "defaultLanguageCode": "en",
            "textSplitMode": "pages",
            "maximumPageLength": 1000,
            "pageOverlapLength": 200,
            "inputs": [
                {
                    "name": "text",
                    "source": "/document/content"
                }
            ],
            "outputs": [
                {
                    "name": "textItems",
                    "targetName": "chunks"
                }
            ]
        },
        {
            "@odata.type": "#Microsoft.Skills.Text.AzureOpenAIEmbeddingSkill",
            "name": "openai-embedding",
            "description": "Generate embeddings using Azure OpenAI",
            "context": "/document/chunks/*",
            "resourceUri": "https://YOUR-OPENAI-RESOURCE.openai.azure.com",
            "apiKey": "YOUR-OPENAI-API-KEY",
            "deploymentId": "text-embedding-3-large",
            "modelName": "text-embedding-3-large",
            "inputs": [
                {
                    "name": "text",
                    "source": "/document/chunks/*"
                }
            ],
            "outputs": [
                {
                    "name": "embedding",
                    "targetName": "chunk_vector"
                }
            ]
        }
    ]
}
```

   > **Warning**: Before creating the skillset, make sure to replace `YOUR-OPENAI-RESOURCE` with your actual Azure OpenAI resource endpoint and `YOUR-OPENAI-API-KEY` with your actual API key in the JSON schema above.

### Task 5: Create an Indexer in Azure AI Search

1. In the Azure AI Search service, select **Indexers** from the left-hand menu and click on **+ Add indexer**.

2. In the **New indexer** pane, enter a name for the indexer (e.g., `Documents2Index-indexer`).

3. For the **Data source**, select the data source you created in Task 2.

4. For the **Target index**, select the index you created in Task 3.

5. For the **Skillset**, select the skillset you created in Task 4.

6. Configure the **Schedule** to run **Once** for testing purposes, or **Hourly** for production scenarios.

7. Click **Save** to save the indexer and start the indexing process.

### Task 6: Check Indexing Status and Validate

1. Go to **"Search explorer"** in your index

2. Run a test query:
```json
{
    "search": "*",
    "top": 5
}
```
3. Verify that the documents have been indexed correctly
4. Review that the `chunk_text`, `chunk_vector`, and `source_url` fields contain data

### Task 7: Test Query Patterns (BM25)

1. In **Search explorer**, run:
```json
{
    "search": "azure cognitive services",
    "searchMode": "all",
    "top": 5,
    "select": "chunk_id,chunk_text,source_url"
}
```
2. Observe the results and relevance score

## Exercise 2: Use Copilot Studio with Azure AI Search

### Task 1: Connect agent to Azure AI Search

1.	To connect our agent to Azure AI Search we will need its **endpoint url** and an **admin key**. For the **url** you can find and copy it at the **Overview** page in Azure AI Search Service

    <img src="../images/ai-search/LabAISearch_Picture11.png" width="100%" height="100%">

    <br>
 
    and for **admin key**, you can find that in **Keys** page. You can copy one of two indifferently

    <br>

    <img src="../images/ai-search/LabAISearch_Picture12.png" width="100%" height="100%"> 

    <br>
 
2. Back to our **Licensing Assistant** agent in Copilot Studio, go to the agent's **Knowledge tab**, click **"Add Knowlege"** button and select **Azure AI Search** in the dialog that appears.

   <img src="../images/ai-search/LabAISearch_Picture13.png" width="100%" height="100%">

   <br>

3. You will have to **create a new connection** and **Add to agent**
   
   <img src="../images/ai-search/LabAISearch_Picture14.png" width="100%" height="100%">

   <br>

You are now ready to test your agent using Azure AI Search as Knowledge source

### Task 3: Use Azure AI Search in you agent

1. If the **Test copilot** pane is hidden by default, open it by selecting the Test icon.
 
<img src="../images/ai-search/LabAISearch_Picture15.png" width="100%" height="100%">

<br>

2.	Select ... next to the Copilot reset button

<br>
  
3.	At the box **'Ask a question or describe what you need'** prompt in the Test copilot pane, type ‘What are the different licensing options available for Power Platform?’.
 
    <img src="../images/ai-search/LabAISearch_Picture17.png" width="100%" height="100%">

<br>

Notice that 'Activity map’ is displaying along with the answer in Test Pane. Azure AI Search as knowledge source has been used.

Lab is now completed, well done!!!. You can move to the next lab


